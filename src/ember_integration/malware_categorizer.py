import logging
from typing import Dict, Any, List
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
import json
import os
from pathlib import Path

class MalwareCategorizer:
    """Categorizes malware based on extracted features."""
    
    def __init__(self, db_path: str = ""):
        self.logger = logging.getLogger(__name__)
        self.db_path = db_path or os.path.join(os.path.expanduser("~"), "cyber_attack_tracer", "data", "malware_db")
        self.malware_db = {}
        self.feature_scaler = StandardScaler()
        self.clusterer = DBSCAN(eps=0.5, min_samples=2)
        
        # Create database directory if it doesn't exist
        os.makedirs(self.db_path, exist_ok=True)
        
        # Load existing database
        self._load_database()
        
    def _load_database(self):
        """Load malware database from disk."""
        db_file = os.path.join(self.db_path, "malware_db.json")
        if os.path.exists(db_file):
            try:
                with open(db_file, "r") as f:
                    self.malware_db = json.load(f)
                self.logger.info(f"Loaded malware database with {len(self.malware_db)} entries")
            except Exception as e:
                self.logger.error(f"Error loading malware database: {str(e)}")
                self.malware_db = {}
                
    def _save_database(self):
        """Save malware database to disk."""
        db_file = os.path.join(self.db_path, "malware_db.json")
        try:
            with open(db_file, "w") as f:
                json.dump(self.malware_db, f, indent=2)
            self.logger.info(f"Saved malware database with {len(self.malware_db)} entries")
        except Exception as e:
            self.logger.error(f"Error saving malware database: {str(e)}")
            
    def add_sample(self, sample_id: str, features: Dict[str, Any], category: str = None):
        """Add a malware sample to the database."""
        self.malware_db[sample_id] = {
            "features": features,
            "category": category
        }
        self._save_database()
        
    def categorize_sample(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """Categorize a malware sample based on its features."""
        if not self.malware_db:
            return {"category": "unknown", "confidence": 0.0}
            
        # Extract feature vector
        feature_vector = self._extract_feature_vector(features)
        
        # Compare with known samples
        similarities = {}
        for sample_id, sample_data in self.malware_db.items():
            if "features" in sample_data:
                sample_vector = self._extract_feature_vector(sample_data["features"])
                similarity = self._calculate_similarity(feature_vector, sample_vector)
                similarities[sample_id] = similarity
                
        # Find most similar sample
        if similarities:
            most_similar_id = max(similarities, key=similarities.get)
            most_similar_score = similarities[most_similar_id]
            
            if most_similar_score > 0.8:  # High similarity threshold
                category = self.malware_db[most_similar_id].get("category", "unknown")
                return {
                    "category": category,
                    "confidence": most_similar_score,
                    "similar_sample": most_similar_id
                }
                
        # If no high similarity match, try clustering
        return self._cluster_sample(feature_vector)
        
    def _extract_feature_vector(self, features: Dict[str, Any]) -> np.ndarray:
        """Extract a numerical feature vector from feature dictionary."""
        vector = []
        
        # File size
        vector.append(features.get("file_size", 0))
        
        # Entropy
        vector.append(features.get("entropy_analysis", 0))
        
        # Section count
        vector.append(len(features.get("section_info", [])))
        
        # Import count
        import_count = sum(len(imports) for imports in features.get("import_info", {}).values())
        vector.append(import_count)
        
        # Export count
        vector.append(len(features.get("export_info", [])))
        
        # Average section entropy
        if "section_info" in features and features["section_info"]:
            avg_section_entropy = np.mean([section.get("entropy", 0) for section in features["section_info"]])
            vector.append(avg_section_entropy)
        else:
            vector.append(0)
            
        return np.array(vector)
        
    def _calculate_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calculate cosine similarity between two feature vectors."""
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        return np.dot(vec1, vec2) / (norm1 * norm2)
        
    def _cluster_sample(self, feature_vector: np.ndarray) -> Dict[str, Any]:
        """Cluster sample with existing samples to determine category."""
        # Collect feature vectors from database
        feature_vectors = []
        sample_ids = []
        
        for sample_id, sample_data in self.malware_db.items():
            if "features" in sample_data:
                sample_vector = self._extract_feature_vector(sample_data["features"])
                feature_vectors.append(sample_vector)
                sample_ids.append(sample_id)
                
        if not feature_vectors:
            return {"category": "unknown", "confidence": 0.0}
            
        # Add current sample
        feature_vectors.append(feature_vector)
        
        # Scale features
        scaled_features = self.feature_scaler.fit_transform(feature_vectors)
        
        # Cluster
        clusters = self.clusterer.fit_predict(scaled_features)
        
        # Get cluster of current sample
        current_cluster = clusters[-1]
        
        if current_cluster == -1:  # Noise point
            return {"category": "unknown", "confidence": 0.0}
            
        # Find other samples in the same cluster
        cluster_samples = [sample_ids[i] for i in range(len(sample_ids)) if clusters[i] == current_cluster]
        
        if not cluster_samples:
            return {"category": "unknown", "confidence": 0.0}
            
        # Count categories in cluster
        category_counts = {}
        for sample_id in cluster_samples:
            category = self.malware_db[sample_id].get("category", "unknown")
            category_counts[category] = category_counts.get(category, 0) + 1
            
        # Find most common category
        if category_counts:
            most_common_category = max(category_counts, key=category_counts.get)
            confidence = category_counts[most_common_category] / len(cluster_samples)
            
            return {
                "category": most_common_category,
                "confidence": confidence,
                "cluster_id": int(current_cluster),
                "cluster_size": len(cluster_samples) + 1  # +1 for current sample
            }
            
        return {"category": "unknown", "confidence": 0.0}
        
    def identify_attack_technique_trends(self) -> Dict[str, Any]:
        """Identify trends in attack techniques based on categorized malware."""
        if not self.malware_db:
            return {"trends": [], "total_samples": 0}
            
        # Count categories
        category_counts = {}
        for sample_id, sample_data in self.malware_db.items():
            category = sample_data.get("category", "unknown")
            category_counts[category] = category_counts.get(category, 0) + 1
            
        # Calculate percentages
        total_samples = len(self.malware_db)
        trends = []
        
        for category, count in category_counts.items():
            percentage = (count / total_samples) * 100
            trends.append({
                "category": category,
                "count": count,
                "percentage": percentage
            })
            
        # Sort by count
        trends.sort(key=lambda x: x["count"], reverse=True)
        
        return {
            "trends": trends,
            "total_samples": total_samples
        }
