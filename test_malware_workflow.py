"""
Test workflow script for downloading and analyzing malware samples from MalwareBazaar.

This script demonstrates the complete workflow for:
1. Downloading malware samples from MalwareBazaar
2. Analyzing the samples using the Cyber Attack Tracer components
3. Generating knowledge graphs and reports
4. Displaying results in the dashboard

Usage:
    python test_malware_workflow.py

Requirements:
    - MalwareBazaar API key set as environment variable: Malware_Bazzar_personal_key
    - All project dependencies installed
"""

import os
import sys
import json
import logging
import argparse
from datetime import datetime
from pathlib import Path
import requests
import time

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("logs/malware_workflow.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

os.makedirs("logs", exist_ok=True)

SAMPLES_DIR = "samples/malwarebazaar"
METADATA_DIR = f"{SAMPLES_DIR}/metadata"
OUTPUT_DIR = "output/malware_workflow"
os.makedirs(SAMPLES_DIR, exist_ok=True)
os.makedirs(METADATA_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

def get_api_key():
    """Get the MalwareBazaar API key from environment variables."""
    api_key = os.environ.get('Malware_Bazzar_personal_key')
    if not api_key:
        logger.error("Error: MalwareBazaar API key not found.")
        logger.error("Please set the Malware_Bazzar_personal_key environment variable.")
        return None
    logger.info(f"API key found (length: {len(api_key)} characters)")
    return api_key

def download_samples(query_type="get_taginfo", limit=3, tag="ransomware"):
    """
    Download samples from MalwareBazaar.
    
    Args:
        query_type: Type of query (default: get_taginfo)
        limit: Maximum number of samples to retrieve
        tag: Specific malware tag to filter by
    
    Returns:
        List of sample metadata dictionaries
    """
    url = "https://mb-api.abuse.ch/api/v1/"
    api_key = get_api_key()
    
    if not api_key:
        return []
    
    data = {
        "query": query_type,
        "limit": limit
    }
    
    if tag:
        data["tag"] = tag
    
    headers = {
        "API-KEY": api_key,
        "Content-Type": "application/x-www-form-urlencoded"
    }
    
    try:
        logger.info(f"Connecting to MalwareBazaar API...")
        logger.info(f"Request data: {data}")
        response = requests.post(url, data=data, headers=headers, timeout=30)
        
        if response.status_code != 200:
            logger.error(f"HTTP Error: {response.status_code}")
            logger.error(f"Response: {response.text}")
            return []
        
        try:
            result = response.json()
        except json.JSONDecodeError:
            logger.error("Error parsing API response. The server returned invalid JSON.")
            logger.error(f"Response text: {response.text[:500]}...")
            return []
        
        if result.get("query_status") == "ok":
            samples = result.get("data", [])
            logger.info(f"Successfully retrieved {len(samples)} samples")
            return process_samples(samples)
        else:
            error_reason = result.get("query_status")
            logger.error(f"API Error: {error_reason}")
            return []
            
    except requests.exceptions.ConnectionError as e:
        logger.error(f"Connection error: {e}")
        logger.error("Please check your internet connection and try again.")
        return []
    except requests.exceptions.Timeout:
        logger.error("Connection timeout. The server took too long to respond.")
        return []
    except requests.exceptions.RequestException as e:
        logger.error(f"Request error: {e}")
        return []
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        return []

def process_samples(samples):
    """
    Process downloaded samples.
    
    Args:
        samples: List of sample metadata dictionaries
    
    Returns:
        List of processed sample metadata dictionaries
    """
    if not samples:
        logger.warning("No samples found in API response.")
        return []
    
    logger.info(f"Processing {len(samples)} samples...")
    processed_samples = []
    
    for sample in samples:
        sha256_hash = sample.get("sha256_hash")
        if not sha256_hash:
            logger.warning("Sample missing SHA256 hash, skipping.")
            continue
        
        metadata_path = os.path.join(METADATA_DIR, f"{sha256_hash}.json")
        with open(metadata_path, "w") as f:
            json.dump(sample, f, indent=2)
        logger.info(f"Saved metadata to {metadata_path}")
        
        processed_samples.append(sample)
    
    return processed_samples

def analyze_samples(samples):
    """
    Analyze malware samples using the Cyber Attack Tracer components.
    
    Args:
        samples: List of sample metadata dictionaries
    
    Returns:
        Dictionary mapping sample hashes to analysis results
    """
    logger.info(f"Analyzing {len(samples)} samples...")
    
    try:
        from src.ember_integration.malware_categorizer import MalwareCategorizer
        from src.ioc_integration.ioc_analyzer import IOCAnalyzer
        
        malware_categorizer = MalwareCategorizer()
        ioc_analyzer = IOCAnalyzer()
        
        analysis_results = {}
        
        for sample in samples:
            sha256_hash = sample.get("sha256_hash")
            if not sha256_hash:
                continue
                
            logger.info(f"Analyzing sample: {sha256_hash}")
            
            category_result = malware_categorizer.categorize(sample)
            logger.info(f"Sample categorized as: {category_result.get('category', 'Unknown')}")
            
            iocs = ioc_analyzer.extract_iocs(sample)
            logger.info(f"Extracted {len(iocs)} IOCs from sample")
            
            analysis_results[sha256_hash] = {
                "metadata": sample,
                "category": category_result,
                "iocs": iocs
            }
            
        return analysis_results
        
    except ImportError as e:
        logger.error(f"Import error: {e}")
        logger.error("Make sure all required components are installed.")
        return {}
    except Exception as e:
        logger.error(f"Analysis error: {e}")
        return {}

def generate_knowledge_graphs(analysis_results):
    """
    Generate knowledge graphs for analyzed samples.
    
    Args:
        analysis_results: Dictionary mapping sample hashes to analysis results
    
    Returns:
        Dictionary mapping sample hashes to knowledge graph paths
    """
    logger.info(f"Generating knowledge graphs for {len(analysis_results)} samples...")
    
    try:
        from src.knowledge_graph.knowledge_graph_builder import KnowledgeGraphBuilder
        from src.knowledge_graph.graph_visualizer import GraphVisualizer
        
        graph_builder = KnowledgeGraphBuilder()
        graph_visualizer = GraphVisualizer()
        
        graph_paths = {}
        
        for sha256_hash, result in analysis_results.items():
            logger.info(f"Building knowledge graph for sample: {sha256_hash}")
            
            graph = graph_builder.build_from_analysis(result)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            graph_data_path = os.path.join(OUTPUT_DIR, f"graph_{sha256_hash[:8]}_{timestamp}.json")
            with open(graph_data_path, "w") as f:
                json.dump(graph, f, indent=2)
            
            graph_viz_path = os.path.join(OUTPUT_DIR, f"graph_viz_{sha256_hash[:8]}_{timestamp}.html")
            graph_visualizer.visualize(graph, output_path=graph_viz_path)
            
            graph_paths[sha256_hash] = {
                "data": graph_data_path,
                "visualization": graph_viz_path
            }
            
            logger.info(f"Knowledge graph saved to {graph_viz_path}")
            
        return graph_paths
        
    except ImportError as e:
        logger.error(f"Import error: {e}")
        logger.error("Make sure all required components are installed.")
        return {}
    except Exception as e:
        logger.error(f"Graph generation error: {e}")
        return {}

def generate_reports(analysis_results, graph_paths):
    """
    Generate security reports for analyzed samples.
    
    Args:
        analysis_results: Dictionary mapping sample hashes to analysis results
        graph_paths: Dictionary mapping sample hashes to knowledge graph paths
    
    Returns:
        Dictionary mapping sample hashes to report paths
    """
    logger.info(f"Generating reports for {len(analysis_results)} samples...")
    
    try:
        from src.reporting.report_generator import ReportGenerator
        
        report_generator = ReportGenerator()
        
        report_paths = {}
        
        for sha256_hash, result in analysis_results.items():
            logger.info(f"Generating report for sample: {sha256_hash}")
            
            report_data = {
                "analysis": result,
                "graph_path": graph_paths.get(sha256_hash, {}).get("visualization")
            }
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_path = os.path.join(OUTPUT_DIR, f"report_{sha256_hash[:8]}_{timestamp}.html")
            
            report_generator.generate_report(report_data, output_path=report_path)
            
            report_paths[sha256_hash] = report_path
            
            logger.info(f"Report saved to {report_path}")
            
        return report_paths
        
    except ImportError as e:
        logger.error(f"Import error: {e}")
        logger.error("Make sure all required components are installed.")
        return {}
    except Exception as e:
        logger.error(f"Report generation error: {e}")
        return {}

def run_dashboard(analysis_results, graph_paths, report_paths):
    """
    Run the monitoring dashboard with the analyzed samples.
    
    Args:
        analysis_results: Dictionary mapping sample hashes to analysis results
        graph_paths: Dictionary mapping sample hashes to knowledge graph paths
        report_paths: Dictionary mapping sample hashes to report paths
    """
    logger.info("Starting monitoring dashboard...")
    
    try:
        from src.alerting.monitoring_dashboard import run_dashboard_with_data
        
        dashboard_data = {
            "samples": analysis_results,
            "graphs": graph_paths,
            "reports": report_paths
        }
        
        run_dashboard_with_data(dashboard_data)
        
    except ImportError as e:
        logger.error(f"Import error: {e}")
        logger.error("Make sure all required components are installed.")
    except Exception as e:
        logger.error(f"Dashboard error: {e}")

def main():
    """Main function to run the complete malware analysis workflow."""
    parser = argparse.ArgumentParser(description="Test workflow for malware analysis")
    parser.add_argument("--tag", default="ransomware", help="Malware tag to search for")
    parser.add_argument("--limit", type=int, default=3, help="Number of samples to retrieve")
    parser.add_argument("--dashboard", action="store_true", help="Run the dashboard after analysis")
    args = parser.parse_args()
    
    print("=== Cyber Attack Tracer: Malware Analysis Workflow ===")
    print(f"Starting workflow at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print("\n[Step 1] Downloading malware samples...")
    samples = download_samples(query_type="get_taginfo", limit=args.limit, tag=args.tag)
    
    if not samples:
        print("No samples downloaded. Exiting.")
        return False
    
    print(f"Downloaded {len(samples)} samples.")
    
    print("\n[Step 2] Analyzing malware samples...")
    analysis_results = analyze_samples(samples)
    
    if not analysis_results:
        print("Sample analysis failed. Exiting.")
        return False
    
    print(f"Analyzed {len(analysis_results)} samples.")
    
    print("\n[Step 3] Generating knowledge graphs...")
    graph_paths = generate_knowledge_graphs(analysis_results)
    
    if not graph_paths:
        print("Knowledge graph generation failed. Exiting.")
        return False
    
    print(f"Generated {len(graph_paths)} knowledge graphs.")
    
    print("\n[Step 4] Generating security reports...")
    report_paths = generate_reports(analysis_results, graph_paths)
    
    if not report_paths:
        print("Report generation failed. Exiting.")
        return False
    
    print(f"Generated {len(report_paths)} reports.")
    
    if args.dashboard:
        print("\n[Step 5] Starting monitoring dashboard...")
        run_dashboard(analysis_results, graph_paths, report_paths)
    else:
        print("\n=== Analysis Results ===")
        for sha256_hash, result in analysis_results.items():
            sample_name = result["metadata"].get("file_name", sha256_hash)
            category = result["category"].get("category", "Unknown")
            ioc_count = len(result["iocs"])
            
            print(f"\nSample: {sample_name}")
            print(f"SHA256: {sha256_hash}")
            print(f"Category: {category}")
            print(f"IOCs: {ioc_count}")
            
            if sha256_hash in graph_paths:
                print(f"Knowledge Graph: {graph_paths[sha256_hash]['visualization']}")
            
            if sha256_hash in report_paths:
                print(f"Report: {report_paths[sha256_hash]}")
    
    print("\nWorkflow completed successfully.")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
