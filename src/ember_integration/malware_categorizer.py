import logging
from typing import Dict, Any, List, Set, Tuple, Optional
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
import json
import os
from pathlib import Path
from datetime import datetime

class MalwareCategorizer:
    """Categorizes malware based on extracted features and identifies similar malware samples."""
    
    def __init__(self, db_path: str = ""):
        self.logger = logging.getLogger(__name__)
        self.db_path = db_path or os.path.join(os.path.expanduser("~"), "cyber_attack_tracer", "data", "malware_db")
        self.malware_db = {}
        self.feature_scaler = StandardScaler()
        self.clusterer = DBSCAN(eps=0.5, min_samples=2)
        self.behavior_patterns = {}
        
        # Create database directory if it doesn't exist
        os.makedirs(self.db_path, exist_ok=True)
        
        # Load existing database
        self._load_database()
        self._load_behavior_patterns()
        
    def _load_database(self):
        """Load malware database from disk."""
        db_file = os.path.join(self.db_path, "malware_db.json")
        if os.path.exists(db_file):
            try:
                with open(db_file, "r") as f:
                    self.malware_db = json.load(f)
                self.logger.info(f"Loaded malware database with {len(self.malware_db)} entries")
            except Exception as e:
                self.logger.error(f"Error loading malware database: {str(e)}")
                self.malware_db = {}
                
    def _save_database(self):
        """Save malware database to disk."""
        db_file = os.path.join(self.db_path, "malware_db.json")
        try:
            with open(db_file, "w") as f:
                json.dump(self.malware_db, f, indent=2)
            self.logger.info(f"Saved malware database with {len(self.malware_db)} entries")
        except Exception as e:
            self.logger.error(f"Error saving malware database: {str(e)}")
            
    def _load_behavior_patterns(self):
        """Load behavior patterns for malware classification."""
        patterns_file = os.path.join(self.db_path, "behavior_patterns.json")
        try:
            if os.path.exists(patterns_file):
                with open(patterns_file, "r") as f:
                    self.behavior_patterns = json.load(f)
                self.logger.info(f"Loaded {len(self.behavior_patterns)} behavior patterns")
            else:
                self.logger.info("Behavior patterns file not found, creating default patterns")
                self._create_default_behavior_patterns()
        except Exception as e:
            self.logger.error(f"Error loading behavior patterns: {str(e)}")
            self._create_default_behavior_patterns()
            
    def _create_default_behavior_patterns(self):
        """Create default behavior patterns for malware classification."""
        self.behavior_patterns = {
            "ransomware": {
                "file_operations": ["write", "encrypt", "delete"],
                "registry_operations": ["create", "modify"],
                "network_operations": ["connect"],
                "process_operations": ["create"],
                "common_extensions": [".encrypted", ".locked", ".crypted", ".crypt", ".crypto"],
                "common_processes": ["vssadmin.exe", "bcdedit.exe", "wmic.exe"],
                "common_files": ["ransom_note.txt", "how_to_decrypt.html", "README.txt"]
            },
            "trojan": {
                "file_operations": ["write", "hide", "execute"],
                "registry_operations": ["create", "modify"],
                "network_operations": ["connect", "listen"],
                "process_operations": ["create", "inject"],
                "common_processes": ["svchost.exe", "explorer.exe", "rundll32.exe"],
                "common_registry": ["HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Run"]
            },
            "backdoor": {
                "file_operations": ["write", "hide"],
                "registry_operations": ["create", "modify"],
                "network_operations": ["listen", "connect"],
                "process_operations": ["create", "hide"],
                "common_ports": [4444, 1337, 31337, 8080, 443]
            },
            "cryptominer": {
                "file_operations": ["write", "execute"],
                "registry_operations": ["create"],
                "network_operations": ["connect"],
                "process_operations": ["create"],
                "high_cpu_usage": True,
                "common_processes": ["xmrig.exe", "miner.exe", "cryptominer.exe"],
                "common_domains": ["pool.minexmr.com", "xmrpool.eu", "supportxmr.com"]
            },
            "spyware": {
                "file_operations": ["read", "write", "hide"],
                "registry_operations": ["read", "create", "modify"],
                "network_operations": ["connect"],
                "process_operations": ["create", "inject"],
                "keylogging": True,
                "screenshot": True,
                "common_registry": ["HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer"]
            }
        }
        
        patterns_file = os.path.join(self.db_path, "behavior_patterns.json")
        try:
            with open(patterns_file, "w") as f:
                json.dump(self.behavior_patterns, f, indent=2)
            self.logger.info("Saved default behavior patterns")
        except Exception as e:
            self.logger.error(f"Error saving default behavior patterns: {str(e)}")
            
    def add_sample(self, sample_id: str, features: Dict[str, Any], behavior: Dict[str, Any] = None, category: str = None):
        """Add a malware sample to the database with behavior information."""
        self.malware_db[sample_id] = {
            "features": features,
            "behavior": behavior or {},
            "category": category,
            "added_timestamp": datetime.now().isoformat()
        }
        self._save_database()
        
    def categorize_sample(self, features: Dict[str, Any], behavior: Dict[str, Any] = None) -> Dict[str, Any]:
        """Categorize a malware sample based on its features and behavior."""
        if not self.malware_db:
            return {"category": "unknown", "confidence": 0.0}
            
        # Extract feature vector
        feature_vector = self._extract_feature_vector(features)
        
        feature_similarities = {}
        behavior_similarities = {}
        
        for sample_id, sample_data in self.malware_db.items():
            if "features" in sample_data:
                sample_vector = self._extract_feature_vector(sample_data["features"])
                similarity = self._calculate_similarity(feature_vector, sample_vector)
                feature_similarities[sample_id] = similarity
                
            if behavior and "behavior" in sample_data and sample_data["behavior"]:
                behavior_sim = self._calculate_behavior_similarity(behavior, sample_data["behavior"])
                behavior_similarities[sample_id] = behavior_sim
                
        similar_by_features = []
        if feature_similarities:
            sorted_features = sorted(feature_similarities.items(), key=lambda x: x[1], reverse=True)
            similar_by_features = [{"id": s[0], "similarity": s[1]} for s in sorted_features[:5]]
            
        similar_by_behavior = []
        if behavior_similarities:
            sorted_behavior = sorted(behavior_similarities.items(), key=lambda x: x[1], reverse=True)
            similar_by_behavior = [{"id": s[0], "similarity": s[1]} for s in sorted_behavior[:5]]
            
        behavior_pattern_match = None
        if behavior:
            behavior_pattern_match = self._match_behavior_pattern(behavior)
            
        if "tags" in features and features["tags"]:
            tag_category = self._determine_category_from_tags(features["tags"])
            if tag_category != "unknown":
                category = tag_category
                confidence = 0.85
                return {
                    "category": category,
                    "confidence": confidence,
                    "similar_by_features": similar_by_features[:3] if similar_by_features else [],
                    "similar_by_behavior": similar_by_behavior[:3] if similar_by_behavior else [],
                    "behavior_pattern_match": behavior_pattern_match
                }
        
        if behavior_pattern_match and behavior_pattern_match.get("similarity", 0) > 0.6:
            category = behavior_pattern_match["best_match"]
            confidence = behavior_pattern_match["similarity"]
        elif similar_by_behavior and similar_by_behavior[0]["similarity"] > 0.6:  # Lowered threshold
            most_similar_id = similar_by_behavior[0]["id"]
            category = self.malware_db[most_similar_id].get("category", "unknown")
            confidence = similar_by_behavior[0]["similarity"]
        elif similar_by_features and similar_by_features[0]["similarity"] > 0.6:  # Lowered threshold
            most_similar_id = similar_by_features[0]["id"]
            category = self.malware_db[most_similar_id].get("category", "unknown")
            confidence = similar_by_features[0]["similarity"]
        else:
            cluster_result = self._cluster_sample(feature_vector)
            category = cluster_result["category"]
            confidence = cluster_result["confidence"]
            
        return {
            "category": category,
            "confidence": confidence,
            "similar_by_features": similar_by_features,
            "similar_by_behavior": similar_by_behavior,
            "behavior_pattern_match": behavior_pattern_match
        }
        
    def _extract_feature_vector(self, features: Dict[str, Any]) -> np.ndarray:
        """Extract a numerical feature vector from feature dictionary."""
        vector = []
        
        # File size
        vector.append(features.get("file_size", 0))
        
        # Entropy
        vector.append(features.get("entropy_analysis", 0))
        
        # Section count
        vector.append(len(features.get("section_info", [])))
        
        # Import count
        import_count = sum(len(imports) for imports in features.get("import_info", {}).values())
        vector.append(import_count)
        
        # Export count
        vector.append(len(features.get("export_info", [])))
        
        # Average section entropy
        if "section_info" in features and features["section_info"]:
            avg_section_entropy = np.mean([section.get("entropy", 0) for section in features["section_info"]])
            vector.append(avg_section_entropy)
        else:
            vector.append(0)
            
        return np.array(vector)
        
    def _calculate_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calculate cosine similarity between two feature vectors."""
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        return np.dot(vec1, vec2) / (norm1 * norm2)
        
    def _calculate_behavior_similarity(self, behavior1: Dict[str, Any], behavior2: Dict[str, Any]) -> float:
        """Calculate similarity between two behavior patterns."""
        if not behavior1 or not behavior2:
            return 0.0
            
        aspects = [
            "file_operations",
            "registry_operations",
            "network_operations",
            "process_operations",
            "common_processes",
            "common_files",
            "common_registry",
            "common_domains",
            "common_ports"
        ]
        
        aspect_scores = []
        for aspect in aspects:
            if aspect in behavior1 and aspect in behavior2:
                score = self._calculate_list_similarity(behavior1[aspect], behavior2[aspect])
                aspect_scores.append(score)
                
        bool_props = ["high_cpu_usage", "keylogging", "screenshot"]
        for prop in bool_props:
            if prop in behavior1 and prop in behavior2:
                score = 1.0 if behavior1[prop] == behavior2[prop] else 0.0
                aspect_scores.append(score)
                
        if aspect_scores:
            return sum(aspect_scores) / len(aspect_scores)
        return 0.0
        
    def _calculate_list_similarity(self, list1: List[Any], list2: List[Any]) -> float:
        """Calculate Jaccard similarity between two lists."""
        if not list1 or not list2:
            return 0.0
            
        set1 = set(list1)
        set2 = set(list2)
        
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        
        if union == 0:
            return 0.0
            
        return intersection / union
        
    def _match_behavior_pattern(self, behavior: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Match behavior against known behavior patterns."""
        if not behavior or not self.behavior_patterns:
            return None
            
        matches = []
        for pattern_name, pattern in self.behavior_patterns.items():
            similarity = self._calculate_behavior_similarity(behavior, pattern)
            if similarity > 0.5:  # Threshold for pattern matching
                matches.append({
                    "pattern": pattern_name,
                    "similarity": similarity
                })
                
        if not matches:
            return None
            
        matches.sort(key=lambda x: x["similarity"], reverse=True)
        
        return {
            "best_match": matches[0]["pattern"],
            "similarity": matches[0]["similarity"],
            "all_matches": matches
        }
        
    def _cluster_sample(self, feature_vector: np.ndarray) -> Dict[str, Any]:
        """Cluster sample with existing samples to determine category."""
        # Collect feature vectors from database
        feature_vectors = []
        sample_ids = []
        
        for sample_id, sample_data in self.malware_db.items():
            if "features" in sample_data:
                sample_vector = self._extract_feature_vector(sample_data["features"])
                feature_vectors.append(sample_vector)
                sample_ids.append(sample_id)
                
        if not feature_vectors:
            return {"category": "unknown", "confidence": 0.0}
            
        # Add current sample
        feature_vectors.append(feature_vector)
        
        # Scale features
        scaled_features = self.feature_scaler.fit_transform(feature_vectors)
        
        # Cluster
        clusters = self.clusterer.fit_predict(scaled_features)
        
        # Get cluster of current sample
        current_cluster = clusters[-1]
        
        if current_cluster == -1:  # Noise point
            return {"category": "unknown", "confidence": 0.0}
            
        # Find other samples in the same cluster
        cluster_samples = [sample_ids[i] for i in range(len(sample_ids)) if clusters[i] == current_cluster]
        
        if not cluster_samples:
            return {"category": "unknown", "confidence": 0.0}
            
        # Count categories in cluster
        category_counts = {}
        for sample_id in cluster_samples:
            category = self.malware_db[sample_id].get("category", "unknown")
            category_counts[category] = category_counts.get(category, 0) + 1
            
        # Find most common category
        if category_counts:
            most_common_category = max(category_counts, key=category_counts.get)
            confidence = category_counts[most_common_category] / len(cluster_samples)
            
            return {
                "category": most_common_category,
                "confidence": confidence,
                "cluster_id": int(current_cluster),
                "cluster_size": len(cluster_samples) + 1  # +1 for current sample
            }
            
        return {"category": "unknown", "confidence": 0.0}
        
    def _determine_category_from_tags(self, tags: List[str]) -> str:
        """Determine malware category from tags."""
        tag_mapping = {
            "ransomware": ["ransomware", "ransom", "crypto", "locker"],
            "trojan": ["trojan", "backdoor", "rat", "stealer", "banker", "keylogger", "spyware"],
            "botnet": ["botnet", "ddos", "mirai", "gafgyt"],
            "cryptominer": ["miner", "cryptominer", "monero", "xmr"],
            "worm": ["worm", "spreader"],
            "adware": ["adware", "pup", "pua"],
            "dropper": ["dropper", "loader", "downloader"],
            "rootkit": ["rootkit", "bootkit"]
        }
        
        tags_lower = [tag.lower() for tag in tags]
        
        category_matches = {}
        for category, category_tags in tag_mapping.items():
            matches = sum(1 for tag in tags_lower if any(cat_tag in tag for cat_tag in category_tags))
            if matches > 0:
                category_matches[category] = matches
                
        if category_matches:
            return max(category_matches, key=category_matches.get)
        
        return "unknown"
        
    def identify_attack_technique_trends(self) -> Dict[str, Any]:
        """Identify trends in attack techniques based on categorized malware."""
        if not self.malware_db:
            return {"trends": [], "total_samples": 0}
            
        # Count categories
        category_counts = {}
        for sample_id, sample_data in self.malware_db.items():
            category = sample_data.get("category", "unknown")
            category_counts[category] = category_counts.get(category, 0) + 1
            
        # Calculate percentages
        total_samples = len(self.malware_db)
        trends = []
        
        for category, count in category_counts.items():
            percentage = (count / total_samples) * 100
            trends.append({
                "category": category,
                "count": count,
                "percentage": percentage
            })
            
        # Sort by count
        trends.sort(key=lambda x: x["count"], reverse=True)
        
        return {
            "trends": trends,
            "total_samples": total_samples
        }
